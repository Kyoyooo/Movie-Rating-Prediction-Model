{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d59b65-52ef-40a4-85b6-525a79fa9e9a",
   "metadata": {},
   "source": [
    "# Movie Rating Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e3993-9814-40c6-8041-4d1c65e7ecb3",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102bf521-4abf-4aae-9761-7ec4a2abb677",
   "metadata": {},
   "source": [
    "### 1. Nguyễn Đăng Pha\n",
    "- **What difficulties have you encountered?**\n",
    "    + Dữ liệu trong các cột phân loại như `genres` và `mpa` bị mất cân bằng nghiêm trọng (một số thể loại chiếm đa số, một số rất ít), gây khó khăn trong việc giúp mô hình học được các đặc trưng hiếm.\n",
    "    + Miền giá trị của `budget` và `vote_count` rất rộng với độ lệch lớn. Sự xuất hiện của các outliers khiến đồ thị histogram bị lệch, gây nhiễu cho các thuật toán nhạy cảm với quy mô dữ liệu.\n",
    "\n",
    "- **What have you learned?**\n",
    "    + Hiểu và áp dụng các kỹ thuật xử lý dữ liệu thiếu một cách khoa học thay vì chỉ xóa bỏ dữ liệu.\n",
    "    + Sử dụng phân cụm (Clustering) để nhóm dữ liệu theo các đặc trưng tương đồng, giúp việc quan sát cấu trúc dữ liệu trở nên trực quan hơn.\n",
    "    + Đưa ra các phương án xử lý dữ liệu khác nhau tùy thuộc vào tính chất của từng đặc trưng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1dce9-84eb-4355-b1e0-34c2926cc75d",
   "metadata": {},
   "source": [
    "### 2. Nguyễn Tuấn Phong\n",
    "- **What difficulties have you encountered?**\n",
    "    + Là người đảm nhận giai đoạn cào dữ liệu cuối cùng (từ index 8001 đến hết), thời gian chờ đợi phản hồi từ server rất lâu (có thể lên tới 8-10 tiếng mỗi lần chạy), đòi hỏi sự kiên nhẫn và khả năng quản lý lỗi kết nối.\n",
    "    + Gặp khó khăn trong việc lựa chọn template và thiết kế slide thuyết trình sao cho vừa đảm bảo tính khoa học, vừa lôi cuốn người xem.\n",
    "- **What have you learned?**\n",
    "    + Kỹ năng cào dữ liệu thủ công khi database không hỗ trợ API.\n",
    "    + Thành thạo các bước chuẩn hóa dữ liệu và xử lý các trường hợp ngoại lệ trong tập dữ liệu thực tế.\n",
    "    + Hiểu rõ sức mạnh của Random Forest so với Linear Regression trong việc xử lý các bài toán có mối quan hệ phi tuyến tính."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef61aae-6d6e-45ce-aaad-06f7ba7b44c3",
   "metadata": {},
   "source": [
    "### 3. Y Nguyên Mlô\n",
    "- **What difficulties have you encountered?**\n",
    "    + Sử dụng Selenium để cào dữ liệu từ IMDb gặp thách thức lớn khi cấu trúc HTML thường xuyên thay đổi. Cơ chế \"50 more\" (load thêm dữ liệu) thay vì phân trang truyền thống khiến việc debug và test code mất nhiều thời gian.\n",
    "- **What have you learned?**\n",
    "    + Ứng dụng Elbow Method để xác định số cụm tối ưu trong K-Means.\n",
    "    + Tiếp cận và sử dụng CatBoost, hiểu được thế mạnh của nó trong việc xử lý các biến phân loại (Categorical data).\n",
    "    + Biết cách so sánh hiệu năng giữa các dòng mô hình khác nhau trên cùng một tập dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efb640-c302-4a34-b3fc-10ce3cf5c7db",
   "metadata": {},
   "source": [
    "### 4. Võ Trần Duy Hoàng\n",
    "- **What difficulties have you encountered?**\n",
    "    + Đảm bảo tính nhất quán giữa lý thuyết thống kê và thực thi mã nguồn. Đặc biệt là việc chứng minh tại sao mô hình này lại tốt hơn mô hình kia thông qua các chỉ số như RMSE và R-squared.\n",
    "    + Việc tinh chỉnh mô hình Random Forest qua GridSearchCV đòi hỏi sự hiểu biết sâu về các tham số để tránh hiện tượng Overfitting trong khi vẫn phải đảm bảo thời gian tính toán hợp lý.\n",
    "    + Đối mặt với các lỗi kỹ thuật trong quá trình xử lý song song và đảm bảo các bước tiền xử lý (Scaling, Imputation) không gây rò rỉ dữ liệu.\n",
    "- **What have you learned?**\n",
    "    + Hiểu sâu về cách bảo toàn cấu trúc phân phối dữ liệu thông qua Multivariate Iterative Imputation. Việc trực quan hóa bằng KDE plot giúp chứng minh MICE bám sát phân phối gốc hơn so với Simple Imputer.\n",
    "    + Làm chủ kỹ thuật K-Fold Cross-Validation và GridSearchCV để tìm ra bộ tham số tối ưu nhất.\n",
    "    + Học cách phân tích ý nghĩa thực tế của các chỉ số."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df9ab7-59b5-46a2-b48c-9cb7f8fa81a5",
   "metadata": {},
   "source": [
    "### 5. Cả nhóm\n",
    "- **What would you do if you had more time?**\n",
    "    + Nhóm sẽ áp dụng các kỹ thuật cân bằng dữ liệu (như SMOTE hoặc Oversampling) và xây dựng thêm nhiều kiến trúc mô hình phức tạp hơn để tìm ra phương án tối ưu nhất.\n",
    "    + Sử dụng các kỹ thuật NLP như TF-IDF hoặc Word2Vec để chuyển đổi cột `genres` thành vector số học thay vì chỉ encode đơn giản, kết hợp với sức mạnh của CatBoost. Thử nghiệm các phương pháp crawl dữ liệu hiệu quả hơn Selenium.\n",
    "    + Tạo thêm các đặc trưng phái sinh (Interaction features) như tỷ lệ `budget/run_time` hoặc `vote_count/release_year` để xem chúng có giúp giải thích thêm sai số của mô hình hay không.\n",
    "    + Thử nghiệm kết hợp (Stacking) nhiều mô hình như XGBoost, LightGBM và Random Forest để đẩy chỉ số $R^2$ lên cao hơn mức 0.6.\n",
    "    + Xây dựng một ứng dụng web đơn giản (sử dụng Streamlit) để người dùng có thể nhập thông tin phim và nhận dự đoán rating ngay lập tức."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
